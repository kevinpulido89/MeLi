{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.language_models.llms import BaseLLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import pandas as pd\n",
    "from core import LLMConfigBuilder, llm_retriever\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LLMConfigBuilder(\n",
    "    family=\"ollama_llms\", model=\"phi3:14b\", ls_project_name=\"meli\", llm_args={\"temperature\": 0}\n",
    ")\n",
    "\n",
    "llm = llm_retriever(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_llm_from_prompt(\n",
    "    llm: BaseLLM | BaseChatModel, prompt: ChatPromptTemplate, input: dict[str, str]\n",
    ") -> str:\n",
    "    \"\"\"This function takes the input and the prompt, creates a chain with\n",
    "    string parser for the output and returns the output from the LLM.\n",
    "\n",
    "    Args:\n",
    "        llm (BaseLLM | BaseChatModel): The LLM to invoke.\n",
    "        prompt (ChatPromptTemplate): The prompt to use.\n",
    "        input (dict[str, str]): The input to the LLM based on the prompt.\n",
    "\n",
    "    Returns:\n",
    "        str: The output from the LLM.\n",
    "    \"\"\"\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    return chain.invoke(input)\n",
    "\n",
    "\n",
    "def send_chat_request(llm: BaseChatModel, query: str) -> str:\n",
    "    response = llm.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "    )\n",
    "    chat_result = response.choices[0].message.content\n",
    "    if not chat_result:\n",
    "        raise ValueError(\"No response from the chat model.\")\n",
    "    return chat_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 0c2bbd9f-454b-412d-8d08-4109586e40ea not found for run 1a7b0f10-7417-4c32-80a3-2ffc2dcbdf93. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package\n"
     ]
    }
   ],
   "source": [
    "# Create a chat prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Usted es un sistema que analiza en español el título de una publicación de un producto que están en venta y a partir de dicho título debe determinar si es un producto que se vende por unidad o en paquete o varias unidades. También puede ayudarse de la descripción para categorizar el producto. Please response ONLY with 3 of the following categories: 'multiple_units' if the product is sold in multiple units, 'single_unit' if the product is sold in a single unit, 'package' if the product is sold in a package.\",\n",
    "        ),\n",
    "        (\"user\", \"Titulo:{title} Descripción:{description}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "answer = invoke_llm_from_prompt(\n",
    "    llm,\n",
    "    prompt,\n",
    "    {\n",
    "        \"title\": \"Kit Para Hacer Rosario Completo. Paquete X 3 Unidades + Foll\",\n",
    "        \"description\": \"\"\"Cada Paquete Contiene:\n",
    "\n",
    "- 60 Pepas en Madera de excelente calidad. Medidas de cada pepa: 7 mm\n",
    "- 1 Crucero Italiano con la imagen de la Virgen Milagrosa.\n",
    "- 1 Cruz con Medalla de San Benito en metal de excelente calidad.\n",
    "- 3 Metros de Hilo Terlenka N° 8\n",
    "- 1 Folleto Plegable de 7 Caras, contienen oraciones, como rezar el rosario, letanías, etc.\"\"\",\n",
    "    },\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizer(llm, prompt, title, description):\n",
    "    return invoke_llm_from_prompt(llm, prompt, {\"title\": title, \"description\": description})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 67dc51e9-ae72-485a-8ecd-37225c38ee8b not found for run 6d390696-9051-4ce3-be50-cbce0963b793. Treating as a root run.\n",
      "Parent run 3f843748-db8e-4902-8549-3987cdcf683a not found for run 99145858-6292-4858-a589-8c83c57d99b0. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MCO648996211</td>\n",
       "      <td>Kit Para Hacer Rosario Completo. Paquete X 3 U...</td>\n",
       "      <td>KIT PARA HACER ROSARIO COMPLETO X 3 PAQUETICOS...</td>\n",
       "      <td>multiple_units</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCO635227822</td>\n",
       "      <td>Unión 16mm (paquete X 30 Unidades)</td>\n",
       "      <td>Sistemas E Irrigaciones te ofrece la Unión 16 ...</td>\n",
       "      <td>paquete</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              title  \\\n",
       "0  MCO648996211  Kit Para Hacer Rosario Completo. Paquete X 3 U...   \n",
       "1  MCO635227822                 Unión 16mm (paquete X 30 Unidades)   \n",
       "\n",
       "                                         description        category  \n",
       "0  KIT PARA HACER ROSARIO COMPLETO X 3 PAQUETICOS...  multiple_units  \n",
       "1  Sistemas E Irrigaciones te ofrece la Unión 16 ...         paquete  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/kevinpulido/Github/MeLi/meli_148.csv\", sep=\";\")\n",
    "\n",
    "df[\"category\"] = df.apply(lambda x: categorizer(llm, prompt, x[\"title\"], x[\"description\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain supports many other chat models. Here, we're using Ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# supports many more optional parameters. Hover on your `ChatOllama(...)`\n",
    "# class to view the latest available supported parameters\n",
    "llm = ChatOllama(model=\"phi3:14b\", temperature=0)\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a short joke about {topic}\")\n",
    "\n",
    "# using LangChain Expressive Language chain syntax\n",
    "# learn more about the LCEL on\n",
    "# /docs/concepts/#langchain-expression-language-lcel\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# for brevity, response is printed in terminal\n",
    "print(chain.invoke({\"topic\": \"Space travel\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = send_chat_request(llm, query=\"What is Mercado Libre?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"/Users/kevinpulido/Github/MeLi/meli_150.csv\", sep=\";\")\n",
    "df2 = pd.read_csv(\"/Users/kevinpulido/Github/MeLi/meli.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_products = df1.merge(df2, on=\"id\", how=\"left\", suffixes=(\"1\", \"\")).filter([\"id\", \"title\"])\n",
    "country_products.to_csv(\"/Users/kevinpulido/Github/MeLi/meli_166.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import Country, MercadoLibreItems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meli = MercadoLibreItems(Country(country=\"Colombia\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_products[\"description\"] = country_products[\"id\"].apply(\n",
    "    lambda x: meli.get_product_description(x)[\"plain_text\"]\n",
    ")\n",
    "country_products = country_products.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_products.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_products.to_csv(\"/Users/kevinpulido/Github/MeLi/meli_148.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meli",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
